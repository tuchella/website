---
title: "art as a means to express my emotions"
date: 2017-01-14
color: "#41EAD4"
images: 
    - 04/sad.png
draft: false
---

This is the project I worked on during the *Vorkurs - Musik und Medienkunst* at HKB. More or less an iteration of [composition in U+0044 major](../02). Unfortunately I lost all footage b/c of who I am as a person, so I'll try to briefly describe it here. 

First the main idea: People sit on a piano. With their hands hovering over the keyboard, an algorithmically generated melody is played more or less at the hand's positions. Additionally a webcam is filming the persons face and calculates whether the person is looking happy or sad, which affects the mood of the melody.

With regards to the technology here's the gist: The piano was a Yamah Piano that can be controlled over MIDI, kindly provided by HKB. I reused the composing algorithm from the previous project: a neural network trained on a lot of MIDI-files of Bach's music. The primer sequence was generated based on two parameters. First the position of the hands and second the facial expression. If the person was looking happy it used a major scale, if they looked sad it used a minor scale. For the position I used a [LeapMotion sensor](https://www.leapmotion.com/), for the facial expression analysis the [Affectiva SDK](https://www.affectiva.com/). 

Unfortunately the major/minor primer sequence was not very recognizable but the great thing about neural networks is that we don't need to resort to such simple patterns. A better way to handle this would have been to use two distinct data sets: one with 'happy' music and another one with 'sad' music. In this case it would not be necessary to decide the basis on which to distinguish between the two types of sound. Building useful datasets is a huge task though. On the other hand I could have gone for a simpler approach for the first prototype - like a simple markov-chain based algorithm - and then continue developing the music generation part, after getting a first version to work properly.

Apart from that I am really happy with the results. I think people were intrigued by this new way to interact with the instrument. Well, at least I am. There is so much potential in exploring new ways of combining music and technology and making these two things accessible.